{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## DATA CLEANING."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c926efe6f6955e42"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "           textID                                               text  \\\n0      cb774db0d1                I`d have responded, if I were going   \n1      549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n2      088c60f138                          my boss is bullying me...   \n3      9642c003ef                     what interview! leave me alone   \n4      358bd9e861   Sons of ****, why couldn`t they put them on t...   \n...           ...                                                ...   \n27476  4eac33d1c0   wish we could come see u on Denver  husband l...   \n27477  4f4c4fc327   I`ve wondered about rake to.  The client has ...   \n27478  f67aae2310   Yay good for both of you. Enjoy the break - y...   \n27479  ed167662a5                         But it was worth it  ****.   \n27480  6f7127d9d7     All this flirting going on - The ATG smiles...   \n\n                                           selected_text sentiment  \\\n0                    I`d have responded, if I were going   neutral   \n1                                               Sooo SAD  negative   \n2                                            bullying me  negative   \n3                                         leave me alone  negative   \n4                                          Sons of ****,  negative   \n...                                                  ...       ...   \n27476                                             d lost  negative   \n27477                                      , don`t force  negative   \n27478                          Yay good for both of you.  positive   \n27479                         But it was worth it  ****.  positive   \n27480  All this flirting going on - The ATG smiles. Y...   neutral   \n\n      Time of Tweet Age of User      Country  Population -2020  \\\n0           morning        0-20  Afghanistan          38928346   \n1              noon       21-30      Albania           2877797   \n2             night       31-45      Algeria          43851044   \n3           morning       46-60      Andorra             77265   \n4              noon       60-70       Angola          32866272   \n...             ...         ...          ...               ...   \n27476         night       31-45        Ghana          31072940   \n27477       morning       46-60       Greece          10423054   \n27478          noon       60-70      Grenada            112523   \n27479         night      70-100    Guatemala          17915568   \n27480       morning        0-20       Guinea          13132795   \n\n       Land Area (Km²)  Density (P/Km²)  \n0             652860.0               60  \n1              27400.0              105  \n2            2381740.0               18  \n3                470.0              164  \n4            1246700.0               26  \n...                ...              ...  \n27476         227540.0              137  \n27477         128900.0               81  \n27478            340.0              331  \n27479         107160.0              167  \n27480         246000.0               53  \n\n[27481 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>textID</th>\n      <th>text</th>\n      <th>selected_text</th>\n      <th>sentiment</th>\n      <th>Time of Tweet</th>\n      <th>Age of User</th>\n      <th>Country</th>\n      <th>Population -2020</th>\n      <th>Land Area (Km²)</th>\n      <th>Density (P/Km²)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cb774db0d1</td>\n      <td>I`d have responded, if I were going</td>\n      <td>I`d have responded, if I were going</td>\n      <td>neutral</td>\n      <td>morning</td>\n      <td>0-20</td>\n      <td>Afghanistan</td>\n      <td>38928346</td>\n      <td>652860.0</td>\n      <td>60</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>549e992a42</td>\n      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n      <td>Sooo SAD</td>\n      <td>negative</td>\n      <td>noon</td>\n      <td>21-30</td>\n      <td>Albania</td>\n      <td>2877797</td>\n      <td>27400.0</td>\n      <td>105</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>088c60f138</td>\n      <td>my boss is bullying me...</td>\n      <td>bullying me</td>\n      <td>negative</td>\n      <td>night</td>\n      <td>31-45</td>\n      <td>Algeria</td>\n      <td>43851044</td>\n      <td>2381740.0</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9642c003ef</td>\n      <td>what interview! leave me alone</td>\n      <td>leave me alone</td>\n      <td>negative</td>\n      <td>morning</td>\n      <td>46-60</td>\n      <td>Andorra</td>\n      <td>77265</td>\n      <td>470.0</td>\n      <td>164</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>358bd9e861</td>\n      <td>Sons of ****, why couldn`t they put them on t...</td>\n      <td>Sons of ****,</td>\n      <td>negative</td>\n      <td>noon</td>\n      <td>60-70</td>\n      <td>Angola</td>\n      <td>32866272</td>\n      <td>1246700.0</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>27476</th>\n      <td>4eac33d1c0</td>\n      <td>wish we could come see u on Denver  husband l...</td>\n      <td>d lost</td>\n      <td>negative</td>\n      <td>night</td>\n      <td>31-45</td>\n      <td>Ghana</td>\n      <td>31072940</td>\n      <td>227540.0</td>\n      <td>137</td>\n    </tr>\n    <tr>\n      <th>27477</th>\n      <td>4f4c4fc327</td>\n      <td>I`ve wondered about rake to.  The client has ...</td>\n      <td>, don`t force</td>\n      <td>negative</td>\n      <td>morning</td>\n      <td>46-60</td>\n      <td>Greece</td>\n      <td>10423054</td>\n      <td>128900.0</td>\n      <td>81</td>\n    </tr>\n    <tr>\n      <th>27478</th>\n      <td>f67aae2310</td>\n      <td>Yay good for both of you. Enjoy the break - y...</td>\n      <td>Yay good for both of you.</td>\n      <td>positive</td>\n      <td>noon</td>\n      <td>60-70</td>\n      <td>Grenada</td>\n      <td>112523</td>\n      <td>340.0</td>\n      <td>331</td>\n    </tr>\n    <tr>\n      <th>27479</th>\n      <td>ed167662a5</td>\n      <td>But it was worth it  ****.</td>\n      <td>But it was worth it  ****.</td>\n      <td>positive</td>\n      <td>night</td>\n      <td>70-100</td>\n      <td>Guatemala</td>\n      <td>17915568</td>\n      <td>107160.0</td>\n      <td>167</td>\n    </tr>\n    <tr>\n      <th>27480</th>\n      <td>6f7127d9d7</td>\n      <td>All this flirting going on - The ATG smiles...</td>\n      <td>All this flirting going on - The ATG smiles. Y...</td>\n      <td>neutral</td>\n      <td>morning</td>\n      <td>0-20</td>\n      <td>Guinea</td>\n      <td>13132795</td>\n      <td>246000.0</td>\n      <td>53</td>\n    </tr>\n  </tbody>\n</table>\n<p>27481 rows × 10 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "textID              False\n",
      "text                False\n",
      "selected_text       False\n",
      "sentiment           False\n",
      "Time of Tweet       False\n",
      "Age of User         False\n",
      "Country             False\n",
      "Population -2020    False\n",
      "Land Area (Km²)     False\n",
      "Density (P/Km²)     False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import pandas as pd\n",
    "from nltk import  word_tokenize, pos_tag\n",
    "from nltk.chunk import ne_chunk\n",
    "import nltk\n",
    "\n",
    "TO_DELETE = string.punctuation\n",
    "BASE_DIR_PATH= \"/home/kering/Desktop/ML_DATA/Sentiment_Analysis/train.csv\" \n",
    "\n",
    "file_encoding = 'cp1252'   \n",
    "\n",
    "dataFrame = pd.read_csv(BASE_DIR_PATH, engine=\"python\", encoding=file_encoding)\n",
    "\n",
    "def make_lowercase(text_sentence):\n",
    "    words = [word.lower() for word in text_sentence]    \n",
    "    cleaned_string = \"\".join(words) \n",
    "    return cleaned_string\n",
    "\n",
    "def remove_punctuations(__text):\n",
    "    translator =  str.maketrans('', '', TO_DELETE)\n",
    "    return __text.translate(translator)\n",
    "\n",
    "def stem_text(text_to_stem):\n",
    "    porter = nltk.PorterStemmer( )\n",
    "    return [\n",
    "        porter.stem(word) for word in  text_to_stem.split(\" \") if word\n",
    "    ]\n",
    "\n",
    "import torch\n",
    "class LSTMModel:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "#normalizationa  and stemming in NLTK\n",
    "\n",
    "    \n",
    "dataFrame.sample(5)\n",
    "\n",
    "text = \"This is what John gave me  . A nation blessed with farming ... an example sentence for tokenization. And it comes from kenya\"\n",
    "\n",
    "token_list = word_tokenize(\n",
    "    text=remove_punctuations(make_lowercase(text)),\n",
    "    language=\"english\"\n",
    ")\n",
    "\n",
    "\n",
    "#show the first10 token_list[:10] parts of speech tagging is very essential  for understanding the relationship between the components of speech in a language (how nouns interact with verbs maybe ... ) : adds a pos tags to each word/token\n",
    "\n",
    "tagged_tokens = pos_tag(\n",
    "    tokens= token_list\n",
    "    \n",
    ")\n",
    "\n",
    "#NER uses capitalization to indentify the  names  of   places , people etc.Making the text lowercase everything can have significant  impact.\n",
    "\n",
    "entities = ne_chunk(\n",
    "    tagged_tokens=tagged_tokens\n",
    ")\n",
    "\n",
    "# entities.pprint()\n",
    "display(dataFrame)\n",
    "\n",
    "column_name = 'text'\n",
    "# Drop rows with NaN values in the specified column\n",
    "\n",
    "dataFrame.dropna(subset=[column_name], inplace=True)\n",
    "print(\n",
    "    dataFrame.isnull().any()\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T13:02:21.498181954Z",
     "start_time": "2023-10-13T13:02:21.183708678Z"
    }
   },
   "id": "ac10cdecf9707ef3"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/27480 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e01f327478424713b19003e1f7317abb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nltk.sentiment import  vader, SentimentIntensityAnalyzer\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "__sen_intensity_analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Iterate over the rows  : df.iterrows() creates a list of dataframe rows in form of  pandas series .\n",
    "\n",
    "result = {}\n",
    "for index, row  in tqdm(dataFrame.iterrows(), total= len(dataFrame)):\n",
    "    __text_id = row[\"textID\"]\n",
    "    __text = make_lowercase(\n",
    "        remove_punctuations(row[\"text\"])\n",
    "    ) \n",
    "    result[__text_id]= __sen_intensity_analyzer.polarity_scores(__text)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T13:02:33.830684479Z",
     "start_time": "2023-10-13T13:02:25.664724374Z"
    }
   },
   "id": "9f1b3b46ce58b8b6"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "              neg    neu    pos  compound\ndf3a00aeef  0.000  0.708  0.292    0.7351\nea201d0ed1  0.000  1.000  0.000    0.0000\nf761f6948a  0.192  0.720  0.088   -0.3167\neb4dc14fe5  0.000  0.741  0.259    0.7717\n2593a33505  0.000  0.562  0.438    0.5994",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>neg</th>\n      <th>neu</th>\n      <th>pos</th>\n      <th>compound</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>df3a00aeef</th>\n      <td>0.000</td>\n      <td>0.708</td>\n      <td>0.292</td>\n      <td>0.7351</td>\n    </tr>\n    <tr>\n      <th>ea201d0ed1</th>\n      <td>0.000</td>\n      <td>1.000</td>\n      <td>0.000</td>\n      <td>0.0000</td>\n    </tr>\n    <tr>\n      <th>f761f6948a</th>\n      <td>0.192</td>\n      <td>0.720</td>\n      <td>0.088</td>\n      <td>-0.3167</td>\n    </tr>\n    <tr>\n      <th>eb4dc14fe5</th>\n      <td>0.000</td>\n      <td>0.741</td>\n      <td>0.259</td>\n      <td>0.7717</td>\n    </tr>\n    <tr>\n      <th>2593a33505</th>\n      <td>0.000</td>\n      <td>0.562</td>\n      <td>0.438</td>\n      <td>0.5994</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dataFrame = pd.DataFrame(result).transpose()\n",
    "result_dataFrame.sample(\n",
    "    5\n",
    ")\n",
    "\n",
    "#NB : Reviews in very  handy in text analysis,  That is , if the score  of the review is 5 , then the text sentiment must be more positive than it is negative .\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T12:42:57.771287382Z",
     "start_time": "2023-10-13T12:42:57.076339153Z"
    }
   },
   "id": "f392e24e83206b1d"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "['hello', 'there', 'program', 'is', 'the', 'better', 'thin', 'ever']"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_string = \"Hello there  programing  is the better thin ever ...  : :::  ___++ /**** \"\n",
    "\n",
    "__lstm_model = LSTMModel()\n",
    "\n",
    "processed_text = stem_text(\n",
    "    remove_punctuations(\n",
    "        make_lowercase(\n",
    "            test_string\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "#lemmatization is more powerful  than stemming , as it gives good for a word like better .\n",
    "\n",
    "processed_text\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-13T13:13:35.978527729Z",
     "start_time": "2023-10-13T13:13:35.966793328Z"
    }
   },
   "id": "ba28b1c570eab507"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
