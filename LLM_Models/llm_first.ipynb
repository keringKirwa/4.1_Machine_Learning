{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-14T16:45:23.845200546Z",
     "start_time": "2023-10-14T16:45:21.176355652Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21, 18, 8, 8, 14, 9, 19, 1, 14, 3, 19, 16, 2, 18, 19, 7, 14, 0, 19, 5, 14, 17, 16, 7, 12, 19, 10, 19, 16, 13, 19, 17, 14, 11, 4, 20, 19, 3, 18, 8, 8, 9, 19, 5, 1, 16, 4, 6, 19, 7, 14, 0, 15]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'super' object has no attribute '_CharLM__init'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 41\u001B[0m\n\u001B[1;32m     38\u001B[0m num_epochs \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m100\u001B[39m\n\u001B[1;32m     40\u001B[0m \u001B[38;5;66;03m# Create the model\u001B[39;00m\n\u001B[0;32m---> 41\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mCharLM\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhidden_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_layers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     43\u001B[0m \u001B[38;5;66;03m# Loss and optimizer\u001B[39;00m\n\u001B[1;32m     44\u001B[0m criterion \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mCrossEntropyLoss()\n",
      "Cell \u001B[0;32mIn[5], line 19\u001B[0m, in \u001B[0;36mCharLM.__init__\u001B[0;34m(self, input_size, hidden_size, num_layers, output_size)\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, input_size, hidden_size, num_layers, output_size):\n\u001B[0;32m---> 19\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mCharLM\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__init\u001B[49m()\n\u001B[1;32m     20\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhidden_size \u001B[38;5;241m=\u001B[39m hidden_size\n\u001B[1;32m     21\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_layers \u001B[38;5;241m=\u001B[39m num_layers\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'super' object has no attribute '_CharLM__init'"
     ]
    }
   ],
   "source": [
    "# Define the training data\n",
    "text = \"Hello, how are you today? I am doing well, thank you!\"\n",
    "\n",
    "# Create a vocabulary\n",
    "chars_list= list(set(text))\n",
    "\n",
    "vocab_size = len(chars_list)\n",
    "char_to_index = {char: index for index, char in enumerate(chars_list)}\n",
    "index_to_char = {index: char for index, char in enumerate(chars_list)}\n",
    "\n",
    "# Convert text to a sequence of indices\n",
    "text_as_indices = [char_to_index[char] for char in text]\n",
    "\n",
    "print(text_as_indices)\n",
    "\n",
    "# Define the LSTM-based Language Model\n",
    "class CharLM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, *args, **kwargs):\n",
    "        \n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        super(CharLM, self).__init()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        out = self.embedding(x)\n",
    "        out, hidden = self.lstm(out, hidden)\n",
    "        out = self.fc(out)\n",
    "        return out, hidden\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = vocab_size\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "output_size = vocab_size\n",
    "learning_rate = 0.01\n",
    "num_epochs = 100\n",
    "\n",
    "# Create the model\n",
    "model = CharLM(input_size, hidden_size, num_layers, output_size)\n",
    "\n",
    "# Loss and optimizer\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training the model\n",
    "for epoch in range(num_epochs):\n",
    "    inputs = torch.tensor(text_as_indices[:-1]).unsqueeze(0)\n",
    "    targets = torch.tensor(text_as_indices[1:]).unsqueeze(0)\n",
    "\n",
    "    hidden = (torch.zeros(num_layers, 1, hidden_size),\n",
    "              torch.zeros(num_layers, 1, hidden_size))\n",
    "\n",
    "    outputs, _ = model(inputs, hidden)\n",
    "    loss = criterion(outputs.view(-1, vocab_size), targets.view(-1))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')\n",
    "\n",
    "# Generating text\n",
    "with torch.no_grad():\n",
    "    seed = \"Hello\"\n",
    "    seed_indices = [char_to_index[char] for char in seed]\n",
    "    generated_text = seed\n",
    "\n",
    "    hidden = (torch.zeros(num_layers, 1, hidden_size),\n",
    "              torch.zeros(num_layers, 1, hidden_size))\n",
    "\n",
    "    for _ in range(100):\n",
    "        input_char = torch.tensor(seed_indices[-1]).unsqueeze(0).unsqueeze(0)\n",
    "        output, hidden = model(input_char, hidden)\n",
    "        _, predicted_index = torch.max(output, 2)\n",
    "        next_char = index_to_char[predicted_index.item()]\n",
    "        generated_text += next_char\n",
    "        seed_indices.append(predicted_index.item())\n",
    "\n",
    "    print(generated_text)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-14T16:46:53.499835734Z",
     "start_time": "2023-10-14T16:46:53.414802407Z"
    }
   },
   "id": "6a699a8163a620f1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
