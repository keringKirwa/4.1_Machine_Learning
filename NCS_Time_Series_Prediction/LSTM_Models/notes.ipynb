{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Splitting the Dataframe into X_features and the Y_Classes\n",
    "\"\"\"\n",
    "WINDOW_SIZE = 5\n",
    "[\n",
    "  [[dp1, dh1, dl1], [ds2, dp2], [ds3, dp3], [ds4, dp4], [ds5, dp5]],\n",
    "  [[ds2, dp2], [ds3, dp3], [ds4, dp4], [ds5, dp5], [ds6, dp6]]  \n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "def __generate_x_y_from_nsc_df(__data_frame , time_step=5):\n",
    "    data_array = __data_frame.to_numpy()\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(data_array)-time_step):\n",
    "        \n",
    "        rows = data_array[i : i + time_step]  #Select 5 rows in each and every iteration\n",
    "        zipped_rows = [row for row in rows]  \n",
    "        \n",
    "        label = data_array[i + time_step][0] # Select the sixth row and the first column in that row . NB: Anything that is separated by [] makes rows and not columns .\n",
    "        X.append(zipped_rows)\n",
    "        y.append(label)\n",
    "        \n",
    "    return np.array(X).astype(np.float32), np.array(y).astype(np.float32).reshape(-1,1)\n",
    "\n",
    "X_data, Y_classes = __generate_x_y_from_nsc_df(preprocessed_df , time_step=5)\n",
    "\n",
    "print(\"X_Data shape : \",X_data.shape)\n",
    "print(\"Y_Data shape : \",Y_classes.shape)\n",
    "\n",
    "Y_classes\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f902c0a9ebb05324"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Model Creation and Model Compilation.\n",
    "dropout_rate = 0.2\n",
    "\n",
    "input_shape=(X_data.shape[1], X_data.shape[2])\n",
    "\n",
    "print(\"Input shape : \",input_shape)\n",
    "\n",
    "\n",
    "nsc_lstm_model = Sequential([\n",
    "    Input(input_shape),\n",
    "    LSTM(units=150), \n",
    "    Dense(units=1, activation='linear')\n",
    "])\n",
    "\n",
    "nsc_lstm_model.compile(loss=MeanSquaredError(), \n",
    "              optimizer=Adam(learning_rate=0.0001),\n",
    "              metrics=[RootMeanSquaredError()])\n",
    "\n",
    "plot_model(nsc_lstm_model, show_shapes=True, show_layer_names=True)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "80b2ce144160d38c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "#++++++++++++++++++++++++++++++++++++++++++   SPLITTING DATA +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++#\n",
    "\n",
    "def dynamic_data_split(X, y, ratio_train):\n",
    "    \"\"\"\n",
    "    Splits data and labels into training, validation, and test sets.\n",
    "\n",
    "    Args:\n",
    "        X (a 3D numpy.ndarray): Data.\n",
    "        y (numpy.ndarray): Labels.\n",
    "        ratio_train (float): Ratio for training data.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (X_train, y_train, X_val, y_val, X_test, y_test).\n",
    "    \"\"\"\n",
    "    total_samples = X.shape[0]\n",
    "\n",
    "    train_samples = int(ratio_train * total_samples)\n",
    "    \n",
    "\n",
    "    X_train, y_train = X[:train_samples], y[:train_samples]\n",
    "    X_test, y_test = X[train_samples:], y[train_samples:]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "train_ratio = 0.8\n",
    "test_ratio = 0.2\n",
    "\n",
    "X_train, y_train, X_test, y_test = dynamic_data_split(X_data,Y_classes , train_ratio)\n",
    "\n",
    "X_train.shape,y_train.shape, X_test.shape, y_test.shape\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e876eaee6b58543"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# __nsc_model_checkpoint = ModelCheckpoint('nsc_model/', save_best_only=True)\n",
    "\n",
    "\n",
    "nsc_lstm_model.fit(X_train, y_train,batch_size=30, epochs=100, callbacks=[History()])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e36e9ff1530c5c4c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "test_predictions = nsc_lstm_model.predict(X_test).flatten()\n",
    "\n",
    "test_df = pd.DataFrame(data={'Actuals':y_test.flatten(),'Test Predictions':test_predictions})\n",
    "\n",
    "plt.plot(test_df['Actuals'], color = 'red', label = random_company_code + ' Stock Price')\n",
    "plt.plot(test_df['Test Predictions'], color = 'green', label = 'Predicted ' + random_company_code+' Stock Price')\n",
    "plt.title(random_company_code + ' Ltd. stock market predictions')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel( random_company_code + 'Stock Price')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "test_df\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "38ea05c81e0d040d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "time_series_spliter= TimeSeriesSplit(n_splits=10) #number of splits to be 10, indicating that 10% of the data will serve as the test set\n",
    "\n",
    "\n",
    "\n",
    "for train_index, test_index in time_series_spliter.split(feature_transform):\n",
    "    #.values.ravel() method is used to convert a Pandas Series or DataFrame into a 1D NumPy array\n",
    "    X_train = feature_transform[:len(train_index)]\n",
    "    X_test=  feature_transform[len(train_index): (len(train_index)+len(test_index))]\n",
    "        \n",
    "    y_train = output_var[:len(train_index)].values.ravel()\n",
    "    y_test= output_var[len(train_index): (len(train_index)+len(test_index))].values.ravel()\n",
    "\n",
    "\n",
    "trainX =np.array(X_train)\n",
    "print(trainX.shape)\n",
    "print(y_test.shape)\n",
    "testX =np.array(X_test)\n",
    "X_train = trainX.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "X_test = testX.reshape(X_test.shape[0], 1, X_test.shape[1])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f5d4aae586ff1fa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lstm = Sequential()\n",
    "lstm.add(LSTM(100, input_shape=input_shape, activation='tanh', return_sequences=True))\n",
    "lstm.add(Dropout(.2))\n",
    "lstm.add(LSTM(100, activation='relu', return_sequences=False))\n",
    "lstm.add(Dropout(.2))\n",
    "lstm.add(Dense(1))\n",
    "\n",
    "lstm.compile(loss=MeanSquaredError(), \n",
    "              optimizer=Adam(),\n",
    "              metrics=[RootMeanSquaredError()])\n",
    "\n",
    "lstm.summary()\n",
    "#________________"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7c0415ea81deb61"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "numerical_transformer = Pipeline([\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessing = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, ['NumberOfDeviceRegistered', 'Tenure', 'OrderCount']),\n",
    "        ('cat', categorical_transformer, ['PreferredOrderCat', 'Gender'])\n",
    "    ]\n",
    ")\n",
    "lr_pipe = Pipeline([     \n",
    "    ('nscPreprocessor', __nse_dat_preprocessor)\n",
    "     ('logistic_regression', LogisticRegression()),\n",
    "    \n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "39133bccda19d0f4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
