{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-02T19:08:53.012166839Z",
     "start_time": "2023-11-02T19:08:52.901510853Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Input, InputLayer, Dropout\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "#DATA NORMALIZATION(STANDARDISATION)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#DATA PLOTTING\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#FOR PERFORMANCE METRICS ANALYSIS.\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import  MeanSquaredError\n",
    "from keras.metrics import  RootMeanSquaredError\n",
    "\n",
    "#SAVING AND LOADING MODEL\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "           Date  Code                        Name   12m Low  12m High  \\\n0      3-Jan-22  EGAD                 Eaagads Ltd        10        15   \n1      3-Jan-22  KUKZ                  Kakuzi Plc       355       427   \n2      3-Jan-22  KAPC     Kapchorua Tea Kenya Plc        80       101   \n3      3-Jan-22  LIMT              Limuru Tea Plc       260       360   \n4      3-Jan-22  SASN                  Sasini Plc     16.75      22.6   \n...         ...   ...                         ...       ...       ...   \n6727  31-May-22   MSC    Mumias Sugar Company Ltd      0.27      0.27   \n6728  31-May-22  UNGA              Unga Group Ltd      26.1      36.4   \n6729  31-May-22  SCOM               Safaricom Plc      25.5     45.25   \n6730  31-May-22  FAHR  Stanlib Fahari Income-REIT         5      7.48   \n6731  31-May-22   GLD            ABSA NewGold ETF  1,780.00  2,135.00   \n\n       Day Low  Day High Day Price  Previous Change Change%      Volume  \\\n0         13.5      13.8      13.5      13.5      -       -       4,000   \n1          385       385       385       385      -       -           -   \n2         99.5      99.5      99.5      95.5      4   4.19%         100   \n3          320       320       320       320      -       -           -   \n4         18.7      18.7      18.7      18.7      -       -           -   \n...        ...       ...       ...       ...    ...     ...         ...   \n6727      0.27      0.27      0.27      0.27      -       -           -   \n6728        29        29        29        30     -1   3.33%       2,100   \n6729     25.95     26.45        26     26.25  -0.25   0.95%  20,079,900   \n6730       5.5       5.6      5.56      5.58  -0.02   0.36%      11,700   \n6731  2,135.00  2,135.00  2,135.00  2,135.00      -       -           -   \n\n     Adjusted Price  \n0                 -  \n1                 -  \n2                 -  \n3                 -  \n4                 -  \n...             ...  \n6727              -  \n6728              -  \n6729              -  \n6730              -  \n6731              -  \n\n[6732 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Code</th>\n      <th>Name</th>\n      <th>12m Low</th>\n      <th>12m High</th>\n      <th>Day Low</th>\n      <th>Day High</th>\n      <th>Day Price</th>\n      <th>Previous</th>\n      <th>Change</th>\n      <th>Change%</th>\n      <th>Volume</th>\n      <th>Adjusted Price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3-Jan-22</td>\n      <td>EGAD</td>\n      <td>Eaagads Ltd</td>\n      <td>10</td>\n      <td>15</td>\n      <td>13.5</td>\n      <td>13.8</td>\n      <td>13.5</td>\n      <td>13.5</td>\n      <td>-</td>\n      <td>-</td>\n      <td>4,000</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3-Jan-22</td>\n      <td>KUKZ</td>\n      <td>Kakuzi Plc</td>\n      <td>355</td>\n      <td>427</td>\n      <td>385</td>\n      <td>385</td>\n      <td>385</td>\n      <td>385</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3-Jan-22</td>\n      <td>KAPC</td>\n      <td>Kapchorua Tea Kenya Plc</td>\n      <td>80</td>\n      <td>101</td>\n      <td>99.5</td>\n      <td>99.5</td>\n      <td>99.5</td>\n      <td>95.5</td>\n      <td>4</td>\n      <td>4.19%</td>\n      <td>100</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3-Jan-22</td>\n      <td>LIMT</td>\n      <td>Limuru Tea Plc</td>\n      <td>260</td>\n      <td>360</td>\n      <td>320</td>\n      <td>320</td>\n      <td>320</td>\n      <td>320</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3-Jan-22</td>\n      <td>SASN</td>\n      <td>Sasini Plc</td>\n      <td>16.75</td>\n      <td>22.6</td>\n      <td>18.7</td>\n      <td>18.7</td>\n      <td>18.7</td>\n      <td>18.7</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6727</th>\n      <td>31-May-22</td>\n      <td>MSC</td>\n      <td>Mumias Sugar Company Ltd</td>\n      <td>0.27</td>\n      <td>0.27</td>\n      <td>0.27</td>\n      <td>0.27</td>\n      <td>0.27</td>\n      <td>0.27</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>6728</th>\n      <td>31-May-22</td>\n      <td>UNGA</td>\n      <td>Unga Group Ltd</td>\n      <td>26.1</td>\n      <td>36.4</td>\n      <td>29</td>\n      <td>29</td>\n      <td>29</td>\n      <td>30</td>\n      <td>-1</td>\n      <td>3.33%</td>\n      <td>2,100</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>6729</th>\n      <td>31-May-22</td>\n      <td>SCOM</td>\n      <td>Safaricom Plc</td>\n      <td>25.5</td>\n      <td>45.25</td>\n      <td>25.95</td>\n      <td>26.45</td>\n      <td>26</td>\n      <td>26.25</td>\n      <td>-0.25</td>\n      <td>0.95%</td>\n      <td>20,079,900</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>6730</th>\n      <td>31-May-22</td>\n      <td>FAHR</td>\n      <td>Stanlib Fahari Income-REIT</td>\n      <td>5</td>\n      <td>7.48</td>\n      <td>5.5</td>\n      <td>5.6</td>\n      <td>5.56</td>\n      <td>5.58</td>\n      <td>-0.02</td>\n      <td>0.36%</td>\n      <td>11,700</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>6731</th>\n      <td>31-May-22</td>\n      <td>GLD</td>\n      <td>ABSA NewGold ETF</td>\n      <td>1,780.00</td>\n      <td>2,135.00</td>\n      <td>2,135.00</td>\n      <td>2,135.00</td>\n      <td>2,135.00</td>\n      <td>2,135.00</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n    </tr>\n  </tbody>\n</table>\n<p>6732 rows Ã— 13 columns</p>\n</div>"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsc_data_frame = pd.read_csv(\"NSE_data_all_stocks_2022_jan_to_may (1).csv\")\n",
    "nsc_data_frame"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T19:08:53.014199653Z",
     "start_time": "2023-11-02T19:08:52.949736938Z"
    }
   },
   "id": "643a221fdd673586"
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1065491407967dc4",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T19:08:53.036078486Z",
     "start_time": "2023-11-02T19:08:52.976283358Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "        Date  Code                            Name 12m Low 12m High Day Low  \\\n0 2022-01-03  EGAD                     Eaagads Ltd      10       15    13.5   \n1 2022-01-03  KUKZ                      Kakuzi Plc     355      427     385   \n2 2022-01-03  KAPC         Kapchorua Tea Kenya Plc      80      101    99.5   \n3 2022-01-03  LIMT                  Limuru Tea Plc     260      360     320   \n4 2022-01-03  SASN                      Sasini Plc   16.75     22.6    18.7   \n5 2022-01-03   WTK        Williamson Tea Kenya Plc     125   154.75     132   \n6 2022-01-03  CGEN         Car and General (K) Ltd      10       70   33.95   \n7 2022-01-03  ABSA             ABSA Bank Kenya Plc     8.6    12.95    11.6   \n8 2022-01-03   BKG                    BK Group Plc    24.3       40      29   \n9 2022-01-03  COOP  Co-operative Bank of Kenya Ltd    11.5       14    12.9   \n\n  Day High Day Price Previous  Day_Of_The_Week Day_Name  Day_Sin  Day_Cos  \n0     13.8      13.5     13.5                0   Monday      0.0      1.0  \n1      385       385      385                0   Monday      0.0      1.0  \n2     99.5      99.5     95.5                0   Monday      0.0      1.0  \n3      320       320      320                0   Monday      0.0      1.0  \n4     18.7      18.7     18.7                0   Monday      0.0      1.0  \n5      132       132      130                0   Monday      0.0      1.0  \n6    33.95     33.95    33.95                0   Monday      0.0      1.0  \n7     11.9     11.75    11.85                0   Monday      0.0      1.0  \n8       29        29       29                0   Monday      0.0      1.0  \n9     13.5        13    12.95                0   Monday      0.0      1.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Code</th>\n      <th>Name</th>\n      <th>12m Low</th>\n      <th>12m High</th>\n      <th>Day Low</th>\n      <th>Day High</th>\n      <th>Day Price</th>\n      <th>Previous</th>\n      <th>Day_Of_The_Week</th>\n      <th>Day_Name</th>\n      <th>Day_Sin</th>\n      <th>Day_Cos</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2022-01-03</td>\n      <td>EGAD</td>\n      <td>Eaagads Ltd</td>\n      <td>10</td>\n      <td>15</td>\n      <td>13.5</td>\n      <td>13.8</td>\n      <td>13.5</td>\n      <td>13.5</td>\n      <td>0</td>\n      <td>Monday</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2022-01-03</td>\n      <td>KUKZ</td>\n      <td>Kakuzi Plc</td>\n      <td>355</td>\n      <td>427</td>\n      <td>385</td>\n      <td>385</td>\n      <td>385</td>\n      <td>385</td>\n      <td>0</td>\n      <td>Monday</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2022-01-03</td>\n      <td>KAPC</td>\n      <td>Kapchorua Tea Kenya Plc</td>\n      <td>80</td>\n      <td>101</td>\n      <td>99.5</td>\n      <td>99.5</td>\n      <td>99.5</td>\n      <td>95.5</td>\n      <td>0</td>\n      <td>Monday</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2022-01-03</td>\n      <td>LIMT</td>\n      <td>Limuru Tea Plc</td>\n      <td>260</td>\n      <td>360</td>\n      <td>320</td>\n      <td>320</td>\n      <td>320</td>\n      <td>320</td>\n      <td>0</td>\n      <td>Monday</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2022-01-03</td>\n      <td>SASN</td>\n      <td>Sasini Plc</td>\n      <td>16.75</td>\n      <td>22.6</td>\n      <td>18.7</td>\n      <td>18.7</td>\n      <td>18.7</td>\n      <td>18.7</td>\n      <td>0</td>\n      <td>Monday</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2022-01-03</td>\n      <td>WTK</td>\n      <td>Williamson Tea Kenya Plc</td>\n      <td>125</td>\n      <td>154.75</td>\n      <td>132</td>\n      <td>132</td>\n      <td>132</td>\n      <td>130</td>\n      <td>0</td>\n      <td>Monday</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2022-01-03</td>\n      <td>CGEN</td>\n      <td>Car and General (K) Ltd</td>\n      <td>10</td>\n      <td>70</td>\n      <td>33.95</td>\n      <td>33.95</td>\n      <td>33.95</td>\n      <td>33.95</td>\n      <td>0</td>\n      <td>Monday</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2022-01-03</td>\n      <td>ABSA</td>\n      <td>ABSA Bank Kenya Plc</td>\n      <td>8.6</td>\n      <td>12.95</td>\n      <td>11.6</td>\n      <td>11.9</td>\n      <td>11.75</td>\n      <td>11.85</td>\n      <td>0</td>\n      <td>Monday</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2022-01-03</td>\n      <td>BKG</td>\n      <td>BK Group Plc</td>\n      <td>24.3</td>\n      <td>40</td>\n      <td>29</td>\n      <td>29</td>\n      <td>29</td>\n      <td>29</td>\n      <td>0</td>\n      <td>Monday</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2022-01-03</td>\n      <td>COOP</td>\n      <td>Co-operative Bank of Kenya Ltd</td>\n      <td>11.5</td>\n      <td>14</td>\n      <td>12.9</td>\n      <td>13.5</td>\n      <td>13</td>\n      <td>12.95</td>\n      <td>0</td>\n      <td>Monday</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DATA  CLEANING  # nsc_data_frame.set_index(nsc_data_frame.Date, inplace=True) to update the index  of the dataframe.\n",
    "\n",
    "date_format = '%d-%b-%y'\n",
    "nsc_data_frame.Date = pd.to_datetime(nsc_data_frame['Date'], format=date_format)\n",
    "nsc_data_frame['Day_Of_The_Week'] = nsc_data_frame['Date'].dt.dayofweek\n",
    "\n",
    "nsc_data_frame['Day_Name'] = nsc_data_frame['Date'].dt.day_name()\n",
    "\n",
    "nsc_data_frame = nsc_data_frame.drop(columns=['Change', 'Change%', 'Volume', 'Adjusted Price'])\n",
    "\n",
    "\n",
    "nsc_data_frame['Day_Sin'] = np.sin(2 * np.pi * nsc_data_frame['Day_Of_The_Week']/4.0)\n",
    "nsc_data_frame['Day_Cos'] = np.cos(2 * np.pi * nsc_data_frame['Day_Of_The_Week']/4.0)\n",
    "\n",
    "nsc_data_frame.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "# min_value = egad_data_frame['Day_Of_The_Week'].min()  ------ >> display(egad_data_frame.info())\n",
    "\n",
    "\n",
    "#SELECT THE 1ST COLUMN AND PLOT THE DAY_SINE AGAINST TIME\n",
    "\n",
    "# plt.figure(figsize=(12, 6))  \n",
    "# plt.subplot(1, 2, 1)  # Selects the first subplot\n",
    "# one_company_data_frame['Day_Sin'].plot()\n",
    "# plt.title('Day_Sin Over Time')\n",
    "# \n",
    "# # SELECT THE 2ND COLUMN AND PLOT THE DAY PRICE AGAINST TIME\n",
    "# \n",
    "# plt.subplot(1, 2, 2)  \n",
    "# one_company_data_frame['Day Price'].plot()\n",
    "# plt.title('Day Price Over Time')\n",
    "# \n",
    "# plt.tight_layout()  # To improve subplot spacing\n",
    "# plt.show()\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T19:08:53.039123738Z",
     "start_time": "2023-11-02T19:08:53.016512779Z"
    }
   },
   "id": "5960eac770fa6973"
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "     Code  Day Price  Day High  Day Low\n0    EGAD       0.84      0.96     0.84\n1    EGAD       0.58      0.58     0.58\n2    EGAD       0.58      0.58     0.58\n3    EGAD       0.96      0.96     0.96\n4    EGAD       0.96      0.96     0.96\n..    ...        ...       ...      ...\n97   EGAD       0.82      0.82     0.82\n98   EGAD       0.82      0.82     0.82\n99   EGAD       0.82      0.82     0.82\n100  EGAD       0.82      0.82     0.82\n101  EGAD       0.82      0.82     0.82\n\n[102 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Code</th>\n      <th>Day Price</th>\n      <th>Day High</th>\n      <th>Day Low</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>EGAD</td>\n      <td>0.84</td>\n      <td>0.96</td>\n      <td>0.84</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>EGAD</td>\n      <td>0.58</td>\n      <td>0.58</td>\n      <td>0.58</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>EGAD</td>\n      <td>0.58</td>\n      <td>0.58</td>\n      <td>0.58</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>EGAD</td>\n      <td>0.96</td>\n      <td>0.96</td>\n      <td>0.96</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>EGAD</td>\n      <td>0.96</td>\n      <td>0.96</td>\n      <td>0.96</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>EGAD</td>\n      <td>0.82</td>\n      <td>0.82</td>\n      <td>0.82</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>EGAD</td>\n      <td>0.82</td>\n      <td>0.82</td>\n      <td>0.82</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>EGAD</td>\n      <td>0.82</td>\n      <td>0.82</td>\n      <td>0.82</td>\n    </tr>\n    <tr>\n      <th>100</th>\n      <td>EGAD</td>\n      <td>0.82</td>\n      <td>0.82</td>\n      <td>0.82</td>\n    </tr>\n    <tr>\n      <th>101</th>\n      <td>EGAD</td>\n      <td>0.82</td>\n      <td>0.82</td>\n      <td>0.82</td>\n    </tr>\n  </tbody>\n</table>\n<p>102 rows Ã— 4 columns</p>\n</div>"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Custom Data cleaner \n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import pandas as pd\n",
    "\n",
    "class NSCDataScaler(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self,company_code ,  columns_to_return,columns_to_type_cast_and_scale):\n",
    "        self.company_code = company_code\n",
    "        self.minMaxScaler = MinMaxScaler()\n",
    "        self.to_type_cast_and_scale= columns_to_type_cast_and_scale\n",
    "    \n",
    "        self.to_return= columns_to_return  #same as  columns_to_type_cast but has the company code.\n",
    "        \n",
    "        \n",
    "    def __type_cast_and_scale_xyz_df(self, xyz_data_frame):\n",
    "        for column_name in self.to_type_cast_and_scale:\n",
    "            xyz_data_frame[column_name] = pd.to_numeric(xyz_data_frame[column_name], errors='coerce')\n",
    "        xyz_data_frame[self.to_type_cast_and_scale] = self.minMaxScaler.fit_transform(xyz_data_frame[self.to_type_cast_and_scale])\n",
    "        \n",
    "        return xyz_data_frame[self.to_return]\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "       \n",
    "\n",
    "    def transform(self, X):   \n",
    "        \"\"\"\n",
    "        X - NSC dataFrame\n",
    "        Selects the data for one company , then names it xyz_company_data_frame \n",
    "        NB: Scaler always return columns that are assignable to the dataframe.        \n",
    "        \"\"\"        \n",
    "        \n",
    "        xyz_company_data_frame = nsc_data_frame[nsc_data_frame['Code'] == self.company_code].reset_index(drop=True)\n",
    "        type_converted_xyz_company_df = self.__type_cast_and_scale_xyz_df(\n",
    "            xyz_company_data_frame       \n",
    "        )\n",
    "        \n",
    "        return type_converted_xyz_company_df\n",
    "    \n",
    "__data_scaler = NSCDataScaler(\n",
    "    columns_to_return=['Code','Day Price','Day High', 'Day Low'],\n",
    "    columns_to_type_cast_and_scale=['Day Price','Day High', 'Day Low'],\n",
    "    company_code=\"EGAD\"\n",
    "    )\n",
    "\n",
    "preprocessed_df = __data_scaler.fit_transform(\n",
    "    nsc_data_frame,    \n",
    ")\n",
    "    \n",
    "preprocessed_df\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T19:08:53.268721185Z",
     "start_time": "2023-11-02T19:08:53.040419442Z"
    }
   },
   "id": "b0d826223e0086e8"
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_Data shape :  (97, 5, 4)\n",
      "(97, 5, 4) (97,)\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([['EGAD', 13.5, '13.8', '13.5'],\n       ['EGAD', 12.85, '12.85', '12.85'],\n       ['EGAD', 12.85, '12.85', '12.85'],\n       ['EGAD', 13.8, '13.8', '13.8'],\n       ['EGAD', 13.8, '13.8', '13.8']], dtype=object)"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Splitting the Dataframe into X_features and the Y_Classes\n",
    "\"\"\"\n",
    "WINDOW_SIZE = 5\n",
    "[\n",
    "  [[ds1, dp1], [ds2, dp2], [ds3, dp3], [ds4, dp4], [ds5, dp5]],\n",
    "  [[ds2, dp2], [ds3, dp3], [ds4, dp4], [ds5, dp5], [ds6, dp6]]  \n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "def __generate_x_y_from_nsc_df(__data_frame , time_step=5):\n",
    "    data_array = __data_frame.to_numpy()\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(data_array)-time_step):\n",
    "        \n",
    "        rows = data_array[i:i + time_step]   # print(rowing[1]) gives [12.85  1.] , that is the second row \n",
    "        \n",
    "        zipped_row = [row for row in rows]  # creates a list of nd_arrays .\n",
    "        \n",
    "        label = data_array[i + time_step][0]\n",
    "        X.append(zipped_row)\n",
    "        y.append(label)\n",
    "        \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X_data, Y_classes = __generate_x_y_from_nsc_df(df_interest , 5)\n",
    "\n",
    "print(\"X_Data shape : \",X_data.shape)\n",
    "\n",
    "print(X_data.shape , Y_classes.shape)\n",
    "\n",
    "X_data[0]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T19:08:53.272081430Z",
     "start_time": "2023-11-02T19:08:53.130001046Z"
    }
   },
   "id": "119d615c0161c055"
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ufunc 'divide' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[71], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m#NORMALIZING DATA  Scaling  using the mean and std deviation : the second option is  to make sure that we normalize the data before preprocessing.\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m temp_training_mean \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmean\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_data\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m temp_training_std \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mstd(X_data[:, :, \u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mnormalize_prices\u001B[39m(x_data_frame):\n",
      "File \u001B[0;32m~/Desktop/MachineLearningProjects/KnowledgeBasedSystemsML/KnowledgeBasedSystemsVenv/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504\u001B[0m, in \u001B[0;36mmean\u001B[0;34m(a, axis, dtype, out, keepdims, where)\u001B[0m\n\u001B[1;32m   3501\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   3502\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m mean(axis\u001B[38;5;241m=\u001B[39maxis, dtype\u001B[38;5;241m=\u001B[39mdtype, out\u001B[38;5;241m=\u001B[39mout, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m-> 3504\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_methods\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_mean\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3505\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/MachineLearningProjects/KnowledgeBasedSystemsML/KnowledgeBasedSystemsVenv/lib/python3.10/site-packages/numpy/core/_methods.py:131\u001B[0m, in \u001B[0;36m_mean\u001B[0;34m(a, axis, dtype, out, keepdims, where)\u001B[0m\n\u001B[1;32m    129\u001B[0m         ret \u001B[38;5;241m=\u001B[39m ret\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;241m.\u001B[39mtype(ret \u001B[38;5;241m/\u001B[39m rcount)\n\u001B[1;32m    130\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 131\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[43mret\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mrcount\u001B[49m\n\u001B[1;32m    133\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ret\n",
      "\u001B[0;31mTypeError\u001B[0m: ufunc 'divide' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "#NORMALIZING DATA  Scaling  using the mean and std deviation : the second option is  to make sure that we normalize the data before preprocessing.\n",
    "\n",
    "temp_training_mean = np.mean(X_data[:, :, 0])\n",
    "temp_training_std = np.std(X_data[:, :, 0])\n",
    "\n",
    "\n",
    "def normalize_prices(x_data_frame):\n",
    "    prices_array  = x_data_frame[:, :, 0]    \n",
    "    x_data_frame[:, :, 0] = (prices_array - temp_training_mean) / temp_training_std \n",
    "    return x_data_frame\n",
    "\n",
    "normalized_data = normalize_prices(X_data)\n",
    "\n",
    "normalized_data\n",
    "\n",
    "\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T19:08:53.446635666Z",
     "start_time": "2023-11-02T19:08:53.173702465Z"
    }
   },
   "id": "717652f0ea16fdd8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Model Creation and Model Compilation.\n",
    "dropout_rate = 0.2\n",
    "input_shape=(normalized_data.shape[1], normalized_data.shape[2])\n",
    "\n",
    "nsc_lstm_model = Sequential([Input(input_shape),\n",
    "                    LSTM(units=100, return_sequences=True),\n",
    "                    Dropout(rate=dropout_rate),\n",
    "                    LSTM(units=100, return_sequences=False),\n",
    "                    Dropout(rate= dropout_rate),\n",
    "                    Dense(units=32, activation='relu'),\n",
    "                    Dense(units = 1)])\n",
    "\n",
    "nsc_lstm_model.compile(loss=MeanSquaredError(), \n",
    "              optimizer=Adam(learning_rate=0.0001),\n",
    "              metrics=[RootMeanSquaredError()])\n",
    "\n",
    "nsc_lstm_model.summary()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-02T19:08:53.336391459Z"
    }
   },
   "id": "d0a9f340473242ca"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "#++++++++++++++++++++++++++++++++++++++++++   SPLITTING DATA +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++#\n",
    "\n",
    "def dynamic_data_split(X, y, train_ratio, val_ratio, test_ratio):\n",
    "    \"\"\"\n",
    "    Splits data and labels into training, validation, and test sets.\n",
    "\n",
    "    Args:\n",
    "        X (a 3D numpy.ndarray): Data.\n",
    "        y (numpy.ndarray): Labels.\n",
    "        train_ratio (float): Ratio for training data.\n",
    "        val_ratio (float): Ratio for validation data.\n",
    "        test_ratio (float): Ratio for test data.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (X_train, y_train, X_val, y_val, X_test, y_test).\n",
    "    \"\"\"\n",
    "    total_samples = X.shape[0]\n",
    "\n",
    "    train_samples = int(train_ratio * total_samples)\n",
    "    val_samples = int(val_ratio * total_samples)\n",
    "\n",
    "    X_train, y_train = X[:train_samples], y[:train_samples]\n",
    "    X_val, y_val = X[train_samples:train_samples + val_samples], y[train_samples:train_samples + val_samples]\n",
    "    X_test, y_test = X[train_samples + val_samples:], y[train_samples + val_samples:]\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.1\n",
    "test_ratio = 0.1\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = dynamic_data_split(normalized_data,Y_classes , train_ratio, val_ratio= val_ratio,test_ratio= test_ratio)\n",
    "\n",
    "X_train.shape,y_train.shape, X_val.shape,y_val.shape, X_test.shape, y_test.shape\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-02T19:08:53.377817726Z"
    }
   },
   "id": "89d72568201aa28"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# __nsc_model_checkpoint = ModelCheckpoint('nsc_model/', save_best_only=True)\n",
    "# \n",
    "# nsc_lstm_model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, callbacks=[__nsc_model_checkpoint])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-02T19:08:53.377989916Z"
    }
   },
   "id": "498f42a9e3910ada"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
