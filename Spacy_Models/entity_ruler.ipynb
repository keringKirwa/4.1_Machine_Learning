{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Court Seal\n",
      "District Court of Financial Frauds\n",
      "123 Main Street Anytown USA\n",
      "Date October 19 2023\n",
      "\n",
      "Case No 2023123\n",
      "Plaintiff John Smith\n",
      "Defendant Sarah Johnson\n",
      "\n",
      "JUDGMENT\n",
      "\n",
      "In the matter of the case regarding financial fraud brought before this honorable court having reviewed the evidence and testimony presented by both parties and considered the arguments put forth by their respective legal representatives the court hereby issues the following judgment\n",
      "\n",
      "Background\n",
      "The plaintiff John Smith filed a complaint against the defendant Sarah Johnson accusing her of financial fraud The plaintiff alleged that the defendant engaged in a series of fraudulent financial activities including embezzlement misappropriation of funds and deceptive accounting practices\n",
      "\n",
      "Findings\n",
      "After careful consideration of the evidence presented during the trial this court finds the following\n",
      "\n",
      "1 Misappropriation of Funds The defendant Sarah Johnson has been found guilty of misappropriating funds totaling 500000 from XYZ Corporation where she was employed as the Chief Financial Officer The evidence presented including bank records and witness testimonies clearly supports this finding\n",
      "\n",
      "2 Embezzlement The defendant Sarah Johnson was also found guilty of embezzlement of funds from XYZ Corporation The evidence shows that the defendant willfully diverted these funds for personal gain\n",
      "\n",
      "3 Deceptive Accounting Practices The defendant engaged in deceptive accounting practices which were aimed at concealing the aforementioned fraudulent activities These practices violated accounting and financial reporting standards\n",
      "\n",
      "Decision\n",
      "Based on the findings outlined above this court renders the following decisions\n",
      "\n",
      "1 The defendant Sarah Johnson is hereby found guilty of financial fraud including misappropriation of funds and embezzlement\n",
      "\n",
      "2 The defendant is sentenced to 7 years of imprisonment for her involvement in financial fraud\n",
      "\n",
      "3 The defendant is ordered to make full restitution to XYZ Corporation for the funds misappropriated and embezzled totaling 500000\n",
      "\n",
      "4 The defendant is prohibited from holding any financial or fiduciary positions in any organization for a period of 10 years following her release from imprisonment\n",
      "\n",
      "Conclusion\n",
      "This judgment serves as a reminder that financial fraud will not be tolerated in our society and those who engage in such activities will be held accountable for their actions The court hopes that this decision will deter others from committing similar crimes and promote the principles of honesty and integrity in financial matters\n",
      "\n",
      "Judges Signature\n",
      "Judge Michael Thompson\n",
      "Presiding Judge\n",
      "District Court of Financial Frauds\n"
     ]
    }
   ],
   "source": [
    "import  string\n",
    "import pandas as pd\n",
    "file_path = \"sample_case.txt\"\n",
    "TO_DELETE = string.punctuation\n",
    "\n",
    "    \n",
    "def remove_punctuations(__text):\n",
    "    translator =  str.maketrans('', '', TO_DELETE)\n",
    "    return __text.translate(translator)\n",
    "    \n",
    "\n",
    "with open(file_path, 'r') as file_ptr:        \n",
    "    text = file_ptr.read()\n",
    "    file_ptr.close()\n",
    "\n",
    "processed_text =  remove_punctuations(text)\n",
    "print(processed_text)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T08:21:05.396340146Z",
     "start_time": "2023-10-21T08:21:05.384432035Z"
    }
   },
   "id": "cbc8d3be05a945cd"
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities:\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                Entity        Label\n0   District Court of Financial Frauds          ORG\n1                                  123     CARDINAL\n2                                  USA          GPE\n3                           John Smith       PERSON\n4                        Sarah Johnson       PERSON\n5                           John Smith       PERSON\n6                        Sarah Johnson       PERSON\n7                      Findings\\nAfter  WORK_OF_ART\n8                                    1     CARDINAL\n9                        Sarah Johnson       PERSON\n10                              500000     CARDINAL\n11                     XYZ Corporation          ORG\n12                                   2     CARDINAL\n13                       Sarah Johnson       PERSON\n14                     XYZ Corporation          ORG\n15                                   3     CARDINAL\n16      Deceptive Accounting Practices          ORG\n17                                   1     CARDINAL\n18                       Sarah Johnson       PERSON\n19                                   2     CARDINAL\n20                             7 years         DATE\n21                                   3     CARDINAL\n22                     XYZ Corporation          ORG\n23                              500000     CARDINAL\n24                                   4     CARDINAL\n25                         a period of         DATE\n26                            10 years         DATE\n27                    Judges Signature  WORK_OF_ART\n28                    Michael Thompson       PERSON\n29  District Court of Financial Frauds          ORG",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Entity</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>District Court of Financial Frauds</td>\n      <td>ORG</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>123</td>\n      <td>CARDINAL</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>USA</td>\n      <td>GPE</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>John Smith</td>\n      <td>PERSON</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Sarah Johnson</td>\n      <td>PERSON</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>John Smith</td>\n      <td>PERSON</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Sarah Johnson</td>\n      <td>PERSON</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Findings\\nAfter</td>\n      <td>WORK_OF_ART</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1</td>\n      <td>CARDINAL</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Sarah Johnson</td>\n      <td>PERSON</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>500000</td>\n      <td>CARDINAL</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>XYZ Corporation</td>\n      <td>ORG</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>2</td>\n      <td>CARDINAL</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Sarah Johnson</td>\n      <td>PERSON</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>XYZ Corporation</td>\n      <td>ORG</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>3</td>\n      <td>CARDINAL</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Deceptive Accounting Practices</td>\n      <td>ORG</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>1</td>\n      <td>CARDINAL</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Sarah Johnson</td>\n      <td>PERSON</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>2</td>\n      <td>CARDINAL</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>7 years</td>\n      <td>DATE</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>3</td>\n      <td>CARDINAL</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>XYZ Corporation</td>\n      <td>ORG</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>500000</td>\n      <td>CARDINAL</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>4</td>\n      <td>CARDINAL</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>a period of</td>\n      <td>DATE</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>10 years</td>\n      <td>DATE</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>Judges Signature</td>\n      <td>WORK_OF_ART</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>Michael Thompson</td>\n      <td>PERSON</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>District Court of Financial Frauds</td>\n      <td>ORG</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Relationships:\n"
     ]
    },
    {
     "data": {
      "text/plain": "        Subject           Action\n0         court         reviewed\n1     arguments              put\n2         court           issues\n3       Johnson         accusing\n4     plaintiff          alleged\n5     defendant          engaged\n6         court            finds\n7      evidence         supports\n8      evidence            shows\n9     defendant         diverted\n10    defendant          engaged\n11    practices         violated\n12    defendant               is\n13  restitution  misappropriated\n14     judgment           serves\n15          who           engage\n16        court            hopes\n17     decision            deter",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Subject</th>\n      <th>Action</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>court</td>\n      <td>reviewed</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>arguments</td>\n      <td>put</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>court</td>\n      <td>issues</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Johnson</td>\n      <td>accusing</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>plaintiff</td>\n      <td>alleged</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>defendant</td>\n      <td>engaged</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>court</td>\n      <td>finds</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>evidence</td>\n      <td>supports</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>evidence</td>\n      <td>shows</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>defendant</td>\n      <td>diverted</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>defendant</td>\n      <td>engaged</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>practices</td>\n      <td>violated</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>defendant</td>\n      <td>is</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>restitution</td>\n      <td>misappropriated</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>judgment</td>\n      <td>serves</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>who</td>\n      <td>engage</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>court</td>\n      <td>hopes</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>decision</td>\n      <td>deter</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "from tqdm import tqdm\n",
    "from textblob import  TextBlob\n",
    "\n",
    "\n",
    "model = spacy.load(\"en_core_web_sm\")\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(processed_text)\n",
    "\n",
    "entities = []\n",
    "\n",
    "print(\"Entities:\")\n",
    "for ent in doc.ents:\n",
    "    entities.append(\n",
    "        (ent.text, ent.label_)\n",
    "    )\n",
    "entities_data_frame = pd.DataFrame(\n",
    "    entities,\n",
    "    columns=[\"Entity\", \"Label\"]\n",
    ")\n",
    "display(entities_data_frame)\n",
    "\n",
    "# Extract and print relationships between entities\n",
    "print(\"\\nRelationships:\")\n",
    "subject_action_pairs = []\n",
    "for token in doc:\n",
    "    if token.dep_ == \"nsubj\":\n",
    "        subject = token.text\n",
    "        action = token.head.text\n",
    "        subject_action_pairs.append(\n",
    "            (subject, action)\n",
    "        )\n",
    "data_frame = pd.DataFrame(\n",
    "    subject_action_pairs,\n",
    "    columns=[\"Subject\", \"Action\"]\n",
    ")\n",
    "\n",
    "data_frame\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T08:13:08.897661205Z",
     "start_time": "2023-10-21T08:13:06.947335962Z"
    }
   },
   "id": "663a1199fd3caceb"
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision\n"
     ]
    }
   ],
   "source": [
    "#EXTRACT THE Decision  part in a judgement FILE.\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "assert len(matcher) == 0\n",
    "matcher.add(\"Rule\", [[{\"ORTH\": \"Decision\"}]])\n",
    "assert len(matcher) == 1\n",
    "\n",
    "pattern = [{\"LOWER\": \"finding\"}, {\"LOWER\": \"findings\"}]\n",
    "matcher.add(\"Find_Findings\", [pattern])\n",
    "\n",
    "matches = matcher(doc)\n",
    "\n",
    "print(\n",
    "    doc[matches[0][1]]\n",
    ")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T08:16:12.823867981Z",
     "start_time": "2023-10-21T08:16:12.780204708Z"
    }
   },
   "id": "17900c48f2fdff51"
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": "            VocabLexeme  StartIndex  EndIndex                    Text\n0  14035105279653467510          81        84        John Smith filed\n1  14035105279653467510          89        92  Sarah Johnson accusing",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>VocabLexeme</th>\n      <th>StartIndex</th>\n      <th>EndIndex</th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>14035105279653467510</td>\n      <td>81</td>\n      <td>84</td>\n      <td>John Smith filed</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>14035105279653467510</td>\n      <td>89</td>\n      <td>92</td>\n      <td>Sarah Johnson accusing</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.matcher import Matcher\n",
    "\n",
    "sample_text = \"Kelvin Kering printed a good document.\"\n",
    "\n",
    "nlp_processor = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "matcher = Matcher(nlp_processor.vocab)\n",
    "prop_noun_verb_pattern = [\n",
    "    {\"POS\": \"PROPN\", \"OP\": \"+\"},\n",
    "    {\"POS\": \"VERB\"}\n",
    "]\n",
    "matcher.add(\"PROP_NOUN_FOLLOWED_BY_VERB\", [prop_noun_verb_pattern], greedy=\"LONGEST\")\n",
    "\n",
    "doc2 = nlp_processor(processed_text)\n",
    "matches = matcher(doc2)\n",
    "matches.sort(key=lambda match: match[1])\n",
    "print(len(matches))\n",
    "prop_noun_list = []\n",
    "#tNote: lambdas are used in the filter and the sort methods .The filter means filter_in (return if the following conditions are  emt ...).\n",
    "for match_tuple in matches[:10]:\n",
    "    \n",
    "    span_token=doc2[match_tuple[1]:match_tuple[2]]\n",
    "    # print(type(span_token)) -------> outputs spacy.tokens.span.Span ... Spacy doc is a special list , with word tokens, span tokens and sentences.\n",
    "    \n",
    "    prop_noun_list.append(\n",
    "        (match_tuple[0], match_tuple[1], match_tuple[2],span_token.text)\n",
    "    )\n",
    "    \n",
    "prop_noun_df = pd.DataFrame(\n",
    "    prop_noun_list,\n",
    "    columns=[\"VocabLexeme\", \"StartIndex\", \"EndIndex\", \"Text\"]\n",
    ")\n",
    "prop_noun_df\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T08:13:10.143493913Z",
     "start_time": "2023-10-21T08:13:08.884201359Z"
    }
   },
   "id": "ef0142ae8ee934ce"
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "data": {
      "text/plain": "               Match_Id                                      Quotation\n0  13254208182742973300  'This is indeed a fake product !,' said Alice",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Match_Id</th>\n      <th>Quotation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>13254208182742973300</td>\n      <td>'This is indeed a fake product !,' said Alice</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary PERSON\n"
     ]
    }
   ],
   "source": [
    "#CHALLENGE 3 :  extracting text from the start of one text to another \n",
    "quot_nlp = spacy.load(\"en_core_web_sm\")\n",
    "quot_file_name = \"sample_quotation_test.txt\"\n",
    "speak_lemmas = [\"speak\",\"say\", \"ask\"]\n",
    "\n",
    "with open(quot_file_name, 'r') as file_pointer:        \n",
    "    quotation_text = file_pointer.read()\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "quotation_pattern = [\n",
    "    {\"ORTH\": \"'\"},\n",
    "    {\"IS_ALPHA\": True, \"OP\":\"+\"},\n",
    "    {\"IS_PUNCT\": True, \"OP\":\"*\"},\n",
    "    {\"ORTH\": \"'\"},\n",
    "    {\"POS\": \"VERB\", \"LEMMA\":{\n",
    "        \"IN\":speak_lemmas\n",
    "    }},\n",
    "    {\"POS\": \"PROPN\", \"OP\":\"+\"}\n",
    "]\n",
    "matcher.add(\"QUOTATION_PATTERN\", [quotation_pattern], greedy=\"LONGEST\")\n",
    "\n",
    "quot_doc = quot_nlp(quotation_text)\n",
    "\n",
    "quot_matches_list= matcher(quot_doc)\n",
    "quot_matches_list.sort(key=lambda match: match[1])\n",
    "\n",
    "quot_list = []\n",
    "\n",
    "for match_id, token_start, token_end in quot_matches_list:\n",
    "    span = quot_doc[token_start:token_end]\n",
    "    quot_list.append((match_id,span.text))\n",
    "    \n",
    "quot_data_frame = pd.DataFrame(\n",
    "    quot_list, \n",
    "    columns=[\"Match_Id\",\"Quotation\"]\n",
    ")\n",
    "display(quot_data_frame) \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-21T08:30:23.479122324Z",
     "start_time": "2023-10-21T08:30:22.324896223Z"
    }
   },
   "id": "ab013caedb7715ea"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#CUSTOM COMPONENTS \n",
    "from spacy.language  import Language\n",
    "@Language.component(\"remove_gpe\")\n",
    "def remove_gpe(doc):\n",
    "    original_ents = list(doc.ents)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ ==\"GPE\":\n",
    "            original_ents.remove(ent)\n",
    "    doc.ents = original_ents\n",
    "    return doc\n",
    "    \n",
    "quot_nlp.add_pipe(\"remove_gpe\")\n",
    "nlp.analyze_pipes()\n",
    "test_text = \"Kenya is a good nation . Mary lives in Britain however\"\n",
    "test_doc = quot_nlp(test_text)\n",
    "for ent in test_doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf5ec679ae0be6c0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
